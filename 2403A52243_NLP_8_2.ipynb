{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSxpBS0Z5CZgHpDM43ZWi3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayeshafarheen11/NLP_Ass/blob/main/2403A52243_NLP_8_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corpus\n"
      ],
      "metadata": {
        "id": "woAW4TcILw0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8OdU85U7LaWq"
      },
      "outputs": [],
      "source": [
        "D1 = \"AI is changing the world.\"\n",
        "D2 = \"Machine learning uses data.\"\n",
        "D3 = \"NLP understands text.\"\n",
        "D4 = \"Data needs cleaning.\"\n",
        "D5 = \"Models learn patterns.\"\n",
        "D6 = \"Text can be classified.\"\n",
        "D7 = \"Topics show main ideas.\"\n",
        "D8 = \"SVM is a classifier.\"\n",
        "D9 = \"Cosine measures similarity.\"\n",
        "D10 = \"Good data improves results.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uni Gram count"
      ],
      "metadata": {
        "id": "dJnVTjVINble"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Combine the text from D1, D2, D3, D4\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "\n",
        "# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "#Vocabulary size is length of unigrams\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2tglKlcL2Bh",
        "outputId": "b725f132-dcbf-4f66-bc07-22aea6ddacfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "is: 2\n",
            "data: 2\n",
            "ai: 1\n",
            "changing: 1\n",
            "the: 1\n",
            "world.: 1\n",
            "machine: 1\n",
            "learning: 1\n",
            "uses: 1\n",
            "data.: 1\n",
            "nlp: 1\n",
            "understands: 1\n",
            "text.: 1\n",
            "needs: 1\n",
            "cleaning.: 1\n",
            "models: 1\n",
            "learn: 1\n",
            "patterns.: 1\n",
            "text: 1\n",
            "can: 1\n",
            "be: 1\n",
            "classified.: 1\n",
            "topics: 1\n",
            "show: 1\n",
            "main: 1\n",
            "ideas.: 1\n",
            "svm: 1\n",
            "a: 1\n",
            "classifier.: 1\n",
            "cosine: 1\n",
            "measures: 1\n",
            "similarity.: 1\n",
            "good: 1\n",
            "improves: 1\n",
            "results.: 1\n",
            "Vocabulary Size= 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-Gram Counts"
      ],
      "metadata": {
        "id": "ZKv9yH50Nepi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWQdUh9zM3Vp",
        "outputId": "90a706ab-ab32-4bc0-e649-034b4a84ee76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "ai is: 1\n",
            "is changing: 1\n",
            "changing the: 1\n",
            "the world.: 1\n",
            "world. machine: 1\n",
            "machine learning: 1\n",
            "learning uses: 1\n",
            "uses data.: 1\n",
            "data. nlp: 1\n",
            "nlp understands: 1\n",
            "understands text.: 1\n",
            "text. data: 1\n",
            "data needs: 1\n",
            "needs cleaning.: 1\n",
            "cleaning. models: 1\n",
            "models learn: 1\n",
            "learn patterns.: 1\n",
            "patterns. text: 1\n",
            "text can: 1\n",
            "can be: 1\n",
            "be classified.: 1\n",
            "classified. topics: 1\n",
            "topics show: 1\n",
            "show main: 1\n",
            "main ideas.: 1\n",
            "ideas. svm: 1\n",
            "svm is: 1\n",
            "is a: 1\n",
            "a classifier.: 1\n",
            "classifier. cosine: 1\n",
            "cosine measures: 1\n",
            "measures similarity.: 1\n",
            "similarity. good: 1\n",
            "good data: 1\n",
            "data improves: 1\n",
            "improves results.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tri-Gram Counts"
      ],
      "metadata": {
        "id": "q7qfyJhiNhsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bA70FcCNNtt",
        "outputId": "0bba34c0-7e5a-481d-9148-9437b2ecdd6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "ai is changing: 1\n",
            "is changing the: 1\n",
            "changing the world.: 1\n",
            "the world. machine: 1\n",
            "world. machine learning: 1\n",
            "machine learning uses: 1\n",
            "learning uses data.: 1\n",
            "uses data. nlp: 1\n",
            "data. nlp understands: 1\n",
            "nlp understands text.: 1\n",
            "understands text. data: 1\n",
            "text. data needs: 1\n",
            "data needs cleaning.: 1\n",
            "needs cleaning. models: 1\n",
            "cleaning. models learn: 1\n",
            "models learn patterns.: 1\n",
            "learn patterns. text: 1\n",
            "patterns. text can: 1\n",
            "text can be: 1\n",
            "can be classified.: 1\n",
            "be classified. topics: 1\n",
            "classified. topics show: 1\n",
            "topics show main: 1\n",
            "show main ideas.: 1\n",
            "main ideas. svm: 1\n",
            "ideas. svm is: 1\n",
            "svm is a: 1\n",
            "is a classifier.: 1\n",
            "a classifier. cosine: 1\n",
            "classifier. cosine measures: 1\n",
            "cosine measures similarity.: 1\n",
            "measures similarity. good: 1\n",
            "similarity. good data: 1\n",
            "good data improves: 1\n",
            "data improves results.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts"
      ],
      "metadata": {
        "id": "FdJUQs-qNlBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "word_sequence = \"AI is\"\n",
        "predicted_next_word = predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{word_sequence}', predicted next word: '{predicted_next_word}'\")\n",
        "word_sequence = \"Machine learning .\"\n",
        "predicted_next_word = predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{word_sequence}', predicted next word: '{predicted_next_word}'\")\n",
        "word_sequence = \"NLP understands .\"\n",
        "predicted_next_word = predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{word_sequence}', predicted next word: '{predicted_next_word}'\")\n",
        "word_sequence = \"Deep learning .\"\n",
        "predicted_next_word = predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{word_sequence}', predicted next word: '{predicted_next_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXCD01gHNrNv",
        "outputId": "3a16ecfa-6ac8-4b25-df5f-9baec22cae1b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  changing is  0.5\n",
            "probability of  a is  0.5\n",
            "Given sequence: 'AI is', predicted next word: 'changing'\n",
            "Given sequence: 'Machine learning .', predicted next word: 'No bigram found starting with '.'.'\n",
            "Given sequence: 'NLP understands .', predicted next word: 'No bigram found starting with '.'.'\n",
            "Given sequence: 'Deep learning .', predicted next word: 'No bigram found starting with '.'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Bi-Gram Model"
      ],
      "metadata": {
        "id": "uKq0KX16PZP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ip_text=input(\"enter text\")\n",
        "predicted_next_word= predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{predicted_next_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQZpOCDnQzMU",
        "outputId": "1f353f27-2ab5-4509-eb18-a73714752dba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textNLP understands\n",
            "probability of  text. is  1.0\n",
            "Given sequence: 'NLP understands', predicted next word: 'text.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts"
      ],
      "metadata": {
        "id": "P9hSGSKeRMoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"AI is changing the\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Machine learning uses\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"NLP understands the\"\n",
        "next_word3 = predict_next_word_trigram(sequence3, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgvsTYwwRPbr",
        "outputId": "39a6b3f0-9d1e-4618-f5a0-52575c281f11"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  world. is  1.0\n",
            "Given sequence: 'AI is changing the', predicted next word: 'world.'\n",
            "probability of  data. is  1.0\n",
            "Given sequence: 'Machine learning uses', predicted next word: 'data.'\n",
            "Given sequence: 'NLP understands the', predicted next word: 'No trigram found starting with 'understands the'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Tri-Gram Mode"
      ],
      "metadata": {
        "id": "2TH_ON7aSnx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "predicted_next_word = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{predicted_next_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7amdcNqSlxE",
        "outputId": "c9c20644-99c4-4c3c-ada1-06666c46558b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textMachine learning\n",
            "probability of  uses is  1.0\n",
            "Given sequence: 'Machine learning', predicted next word: 'uses'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening"
      ],
      "metadata": {
        "id": "15p6XNb6TTzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"AI changing\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Machine learning \"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"NLP understands\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"DEEP learning \"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH7n35NGTV1f",
        "outputId": "b2536166-12ba-4576-8597-ea351a88cb2f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of the is  0.05555555555555555\n",
            "Given sequence: 'AI changing', predicted next word: 'the'\n",
            "probability of uses is  0.05555555555555555\n",
            "Given sequence: 'Machine learning ', predicted next word: 'uses'\n",
            "probability of text. is  0.05555555555555555\n",
            "Given sequence: 'NLP understands', predicted next word: 'text.'\n",
            "probability of uses is  0.05555555555555555\n",
            "Given sequence: 'DEEP learning ', predicted next word: 'uses'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "O5sjtl2fTo97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "predicted_next_word=predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{predicted_next_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYoqbNXdTqm4",
        "outputId": "3a9cd820-6161-42f6-eea9-562e3a24a7fb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textMAchine Learning\n",
            "probability of uses is  0.05555555555555555\n",
            "Given sequence: 'MAchine Learning', predicted next word: 'uses'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts based on laplace smoothening"
      ],
      "metadata": {
        "id": "35pnu71kUnfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"AI is changing \"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "sequence2 = \"Machine learning uses\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "sequence3 = \"NLP understands \"\n",
        "next_word3 = predict_next_word_trigram_Laplace(sequence3, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJKF3vipUuJd",
        "outputId": "c0283371-4b4d-40b5-dd01-dc5f3fc90af6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  the is  0.05555555555555555\n",
            "Given sequence: 'AI is changing ', predicted next word: 'the'\n",
            "probability of  data. is  0.05555555555555555\n",
            "Given sequence: 'Machine learning uses', predicted next word: 'data.'\n",
            "probability of  text. is  0.05555555555555555\n",
            "Given sequence: 'NLP understands ', predicted next word: 'text.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "2zEdTbDXU-aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX7gARtOWIub",
        "outputId": "872c5430-c9d9-49b6-b967-bee0b87bdc52"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is changing\n",
            "probability of  the is  0.05555555555555555\n",
            "Given sequence: 'AI is changing', predicted next word: 'the'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "aX3WvZ9VWVE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"AI changing\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "sequence2 = \"Machine learning uses.\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "word_sequence = \"NLP understands text.\"\n",
        "predicted_next_word = predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{word_sequence}', predicted next word: '{predicted_next_word}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8APVzk1lWX7V",
        "outputId": "8e48c7b5-d78e-4f22-c48b-03f4d2931ea7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of the is  0.08108108108108109\n",
            "Given sequence: 'AI changing', predicted next word: 'the'\n",
            "Given sequence: 'Machine learning uses.', predicted next word: 'No bigram found starting with 'uses.'.'\n",
            "probability of data is  0.08108108108108109\n",
            "Given sequence: 'NLP understands text.', predicted next word: 'data'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "BFYJOgzsXHGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "sequence1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{sequence1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrSbZRI9XI0i",
        "outputId": "c5973f59-f496-4f2e-9175-ea6c57cc37a5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is\n",
            "probability of changing is  0.07692307692307693\n",
            "probability of a is  0.07692307692307693\n",
            "Given sequence: 'AI is', predicted next word: 'changing'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "h2XklwJYXYfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"AI is changing the\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "sequence2 = \"Machine learning uses\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpLRsF11Xazq",
        "outputId": "e8600c66-0c21-4133-ca9d-5f9964799a19"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  world. is  0.08108108108108109\n",
            "Given sequence: 'AI is changing the', predicted next word: 'world.'\n",
            "probability of  data. is  0.08108108108108109\n",
            "Given sequence: 'Machine learning uses', predicted next word: 'data.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "4UH2pcytX_TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "sequence1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{sequence1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwJgvAcYBEe",
        "outputId": "f397a061-1cec-4f1d-b686-ce4f776ca105"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textAI is\n",
            "probability of  changing is  0.08108108108108109\n",
            "Given sequence: 'AI is', predicted next word: 'changing'\n"
          ]
        }
      ]
    }
  ]
}