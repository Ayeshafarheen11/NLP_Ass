{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayeshafarheen11/NLP_Ass/blob/main/Medical_Text_Preprocessing_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2h0g8Dj67EO",
        "outputId": "88829593-6922-4134-8e5a-5d36e90a86f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "id": "HOEIVqO87SwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSdmUeo67c2C",
        "outputId": "b4911cbe-5c20-44bf-fbca-461783ebbb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medical_text = \"\"\"\n",
        "Diabetes mellitus is a chronic condition characterized by elevated blood glucose levels.\n",
        "Patients with diabetes often require insulin therapy and lifestyle modifications.\n",
        "Early diagnosis and proper management can prevent complications such as neuropathy,\n",
        "retinopathy, and cardiovascular diseases.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "o9yowqyD7iyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "sentences_nltk = sent_tokenize(medical_text)\n",
        "print(\"NLTK Sentence Tokenization:\")\n",
        "sentences_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAOcmTm47oF3",
        "outputId": "fbfb4b94-6a50-47a5-9f16-88041f21b62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nDiabetes mellitus is a chronic condition characterized by elevated blood glucose levels.',\n",
              " 'Patients with diabetes often require insulin therapy and lifestyle modifications.',\n",
              " 'Early diagnosis and proper management can prevent complications such as neuropathy,\\nretinopathy, and cardiovascular diseases.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_nltk = sent_tokenize(medical_text)\n",
        "print(\"NLTK Sentence Tokenization:\")\n",
        "sentences_nltk\n"
      ],
      "metadata": {
        "id": "wpJdEBHD73rx",
        "outputId": "e04b89fe-b94d-4239-837b-79e2d0390f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nDiabetes mellitus is a chronic condition characterized by elevated blood glucose levels.',\n",
              " 'Patients with diabetes often require insulin therapy and lifestyle modifications.',\n",
              " 'Early diagnosis and proper management can prevent complications such as neuropathy,\\nretinopathy, and cardiovascular diseases.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_nltk = word_tokenize(medical_text)\n",
        "print(\"NLTK Word Tokenization:\")\n",
        "words_nltk\n"
      ],
      "metadata": {
        "id": "CPejaDhT8C4f",
        "outputId": "918e5331-931f-4038-f8c9-dbacd84d21ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Word Tokenization:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Diabetes',\n",
              " 'mellitus',\n",
              " 'is',\n",
              " 'a',\n",
              " 'chronic',\n",
              " 'condition',\n",
              " 'characterized',\n",
              " 'by',\n",
              " 'elevated',\n",
              " 'blood',\n",
              " 'glucose',\n",
              " 'levels',\n",
              " '.',\n",
              " 'Patients',\n",
              " 'with',\n",
              " 'diabetes',\n",
              " 'often',\n",
              " 'require',\n",
              " 'insulin',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'lifestyle',\n",
              " 'modifications',\n",
              " '.',\n",
              " 'Early',\n",
              " 'diagnosis',\n",
              " 'and',\n",
              " 'proper',\n",
              " 'management',\n",
              " 'can',\n",
              " 'prevent',\n",
              " 'complications',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathy',\n",
              " ',',\n",
              " 'retinopathy',\n",
              " ',',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'diseases',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(medical_text)\n",
        "\n",
        "sentences_spacy = [sent.text for sent in doc.sents]\n",
        "print(\"spaCy Sentence Tokenization:\")\n",
        "sentences_spacy\n"
      ],
      "metadata": {
        "id": "Fy52aE3m8K1n",
        "outputId": "d4fab6f6-a9a5-47b8-cb01-74de7e5962fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Sentence Tokenization:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nDiabetes mellitus is a chronic condition characterized by elevated blood glucose levels.\\n',\n",
              " 'Patients with diabetes often require insulin therapy and lifestyle modifications.\\n',\n",
              " 'Early diagnosis and proper management can prevent complications such as neuropathy,\\nretinopathy, and cardiovascular diseases.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_spacy = [token.text for token in doc if not token.is_punct]\n",
        "print(\"spaCy Word Tokenization:\")\n",
        "words_spacy\n"
      ],
      "metadata": {
        "id": "3V8Ecyk88Ron",
        "outputId": "720bad68-015b-4150-a723-8a841626be9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Word Tokenization:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " 'Diabetes',\n",
              " 'mellitus',\n",
              " 'is',\n",
              " 'a',\n",
              " 'chronic',\n",
              " 'condition',\n",
              " 'characterized',\n",
              " 'by',\n",
              " 'elevated',\n",
              " 'blood',\n",
              " 'glucose',\n",
              " 'levels',\n",
              " '\\n',\n",
              " 'Patients',\n",
              " 'with',\n",
              " 'diabetes',\n",
              " 'often',\n",
              " 'require',\n",
              " 'insulin',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'lifestyle',\n",
              " 'modifications',\n",
              " '\\n',\n",
              " 'Early',\n",
              " 'diagnosis',\n",
              " 'and',\n",
              " 'proper',\n",
              " 'management',\n",
              " 'can',\n",
              " 'prevent',\n",
              " 'complications',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathy',\n",
              " '\\n',\n",
              " 'retinopathy',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'diseases',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "stemmed_words = [stemmer.stem(word) for word in words_nltk if word.isalpha()]\n",
        "print(\"Stemmed Words:\")\n",
        "stemmed_words\n"
      ],
      "metadata": {
        "id": "m1qEHsoS8Wvu",
        "outputId": "02a2ecb5-4bb9-4342-dc83-bc44268b9e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diabet',\n",
              " 'mellitu',\n",
              " 'is',\n",
              " 'a',\n",
              " 'chronic',\n",
              " 'condit',\n",
              " 'character',\n",
              " 'by',\n",
              " 'elev',\n",
              " 'blood',\n",
              " 'glucos',\n",
              " 'level',\n",
              " 'patient',\n",
              " 'with',\n",
              " 'diabet',\n",
              " 'often',\n",
              " 'requir',\n",
              " 'insulin',\n",
              " 'therapi',\n",
              " 'and',\n",
              " 'lifestyl',\n",
              " 'modif',\n",
              " 'earli',\n",
              " 'diagnosi',\n",
              " 'and',\n",
              " 'proper',\n",
              " 'manag',\n",
              " 'can',\n",
              " 'prevent',\n",
              " 'complic',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathi',\n",
              " 'retinopathi',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'diseas']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [token.lemma_ for token in doc if token.is_alpha]\n",
        "print(\"Lemmatized Words:\")\n",
        "lemmatized_words\n"
      ],
      "metadata": {
        "id": "Cm4J_R4x8bM4",
        "outputId": "440a9def-9a87-4689-9b75-b1bb327ab5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diabetes',\n",
              " 'mellitus',\n",
              " 'be',\n",
              " 'a',\n",
              " 'chronic',\n",
              " 'condition',\n",
              " 'characterize',\n",
              " 'by',\n",
              " 'elevated',\n",
              " 'blood',\n",
              " 'glucose',\n",
              " 'level',\n",
              " 'patient',\n",
              " 'with',\n",
              " 'diabete',\n",
              " 'often',\n",
              " 'require',\n",
              " 'insulin',\n",
              " 'therapy',\n",
              " 'and',\n",
              " 'lifestyle',\n",
              " 'modification',\n",
              " 'early',\n",
              " 'diagnosis',\n",
              " 'and',\n",
              " 'proper',\n",
              " 'management',\n",
              " 'can',\n",
              " 'prevent',\n",
              " 'complication',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathy',\n",
              " 'retinopathy',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'disease']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparison: Stemming vs Lemmatization\n",
        "\n",
        "# Re-defining dependencies needed for this cell to run in isolation\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure NLTK data is downloaded (idempotent, won't re-download if present)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to download the missing resource\n",
        "\n",
        "medical_text = \"\"\"\n",
        "Diabetes mellitus is a chronic condition characterized by elevated blood glucose levels.\n",
        "Patients with diabetes often require insulin therapy and lifestyle modifications.\n",
        "Early diagnosis and proper management can prevent complications such as neuropathy,\n",
        "retinopathy, and cardiovascular diseases.\n",
        "\"\"\"\n",
        "\n",
        "# NLTK Word Tokenization\n",
        "words_nltk = word_tokenize(medical_text)\n",
        "\n",
        "# spaCy setup\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(medical_text)\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words_nltk if word.isalpha()]\n",
        "\n",
        "# Lemmatization\n",
        "lemmatized_words = [token.lemma_ for token in doc if token.is_alpha]\n",
        "\n",
        "# Original comparison code\n",
        "comparison = list(zip(stemmed_words, lemmatized_words[:len(stemmed_words)]))\n",
        "\n",
        "print(\"Stemming vs Lemmatization:\")\n",
        "for s, l in comparison:\n",
        "    print(f\"{s}  -->  {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY2G7A9J-_ZI",
        "outputId": "4d9f9bff-054f-4ea4-972f-40bed3a0c259"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming vs Lemmatization:\n",
            "diabet  -->  diabetes\n",
            "mellitu  -->  mellitus\n",
            "is  -->  be\n",
            "a  -->  a\n",
            "chronic  -->  chronic\n",
            "condit  -->  condition\n",
            "character  -->  characterize\n",
            "by  -->  by\n",
            "elev  -->  elevated\n",
            "blood  -->  blood\n",
            "glucos  -->  glucose\n",
            "level  -->  level\n",
            "patient  -->  patient\n",
            "with  -->  with\n",
            "diabet  -->  diabete\n",
            "often  -->  often\n",
            "requir  -->  require\n",
            "insulin  -->  insulin\n",
            "therapi  -->  therapy\n",
            "and  -->  and\n",
            "lifestyl  -->  lifestyle\n",
            "modif  -->  modification\n",
            "earli  -->  early\n",
            "diagnosi  -->  diagnosis\n",
            "and  -->  and\n",
            "proper  -->  proper\n",
            "manag  -->  management\n",
            "can  -->  can\n",
            "prevent  -->  prevent\n",
            "complic  -->  complication\n",
            "such  -->  such\n",
            "as  -->  as\n",
            "neuropathi  -->  neuropathy\n",
            "retinopathi  -->  retinopathy\n",
            "and  -->  and\n",
            "cardiovascular  -->  cardiovascular\n",
            "diseas  -->  disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF Question"
      ],
      "metadata": {
        "id": "hrB0SgKuA_0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlH5Epvh_rEs",
        "outputId": "8e86db59-0aa0-4ead-9976-11243bcd9f13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab') # Add this line to download the missing resource\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "sentence = \"NLP models are transforming the world rapidly!\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "stemmed = [PorterStemmer().stem(w) for w in tokens]\n",
        "lemmatized = [WordNetLemmatizer().lemmatize(w) for w in tokens]\n",
        "\n",
        "print(tokens)\n",
        "print(stemmed)\n",
        "print(lemmatized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLlRIcw__vC1",
        "outputId": "d1313efc-8c9d-4f5a-cc24-56ebf48fb874"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']\n",
            "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli', '!']\n",
            "['NLP', 'model', 'are', 'transforming', 'the', 'world', 'rapidly', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class assignment"
      ],
      "metadata": {
        "id": "O2Qs7V6fA7yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\""
      ],
      "metadata": {
        "id": "e5XKladm_2SU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U75bOzI0_3_O",
        "outputId": "360a44d6-5aea-41c6-c67a-2cef70e44ea9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbewcRVG_7Yh",
        "outputId": "3a427bc2-3585-4dd9-fa68-f51a27d060e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.',\n",
              " 'It is in 150 acres, with both separate hostel facilities for boys and girls.',\n",
              " 'There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI4qUtgO_-WX",
        "outputId": "41cf849e-e020-4b96-f376-d4d411b4953c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbuRcF0DAB3z",
        "outputId": "4112deaa-c364-4732-8217-f2487a0d286f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntt_L2Y2AG7E",
        "outputId": "2a6b24a3-72c1-4694-ec48-1a86b97c621e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'located',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'boys',\n",
              " 'girls',\n",
              " '.',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPHKgQ5dAMXa",
        "outputId": "a089ca1c-b447-4c16-8f02-c0afef51305f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'sr',\n",
              " 'univers',\n",
              " 'campu',\n",
              " 'is',\n",
              " 'locat',\n",
              " 'in',\n",
              " 'ananthasagar',\n",
              " 'villag',\n",
              " 'of',\n",
              " 'hasanparthi',\n",
              " 'mandal',\n",
              " 'in',\n",
              " 'warang',\n",
              " ',',\n",
              " 'telangana',\n",
              " ',',\n",
              " 'india',\n",
              " '.',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acr',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separ',\n",
              " 'hostel',\n",
              " 'facil',\n",
              " 'for',\n",
              " 'boy',\n",
              " 'and',\n",
              " 'girl',\n",
              " '.',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'librari',\n",
              " 'along',\n",
              " 'with',\n",
              " 'india',\n",
              " 'largest',\n",
              " 'technolog',\n",
              " 'busi',\n",
              " 'incub',\n",
              " '(',\n",
              " 'tbi',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'citi',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-XfqCM4APQK",
        "outputId": "7faf6d67-4206-4ef8-9cd9-e93dc683dd4d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Telangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> There\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> library\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> Indias\n",
            "largest ---> largest\n",
            "Technology ---> Technology\n",
            "Business ---> Business\n",
            "Incubator ---> Incubator\n",
            "( ---> (\n",
            "TBI ---> TBI\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yiS5cXQ7ARmd",
        "outputId": "e7740f67-7382-46e0-a71a-5b385a556a5c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Shvb6W70AXaI",
        "outputId": "ab7395e1-a55a-41dc-9f2e-d4c3e0619ec5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparison"
      ],
      "metadata": {
        "id": "7nhTWjjfAxAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer','WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word),lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdtF0Z1MAZTl",
        "outputId": "ab66b296-bf6c-465a-90cb-c268570368d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNetLemmatizer                                 \n",
            "friend              friend              friend              friend                        frind                                   friend                                            \n",
            "friendship          friendship          friendship          friend                        frindship                               friendship                                        \n",
            "friends             friend              friend              friend                        frinds                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        frindships                              friendship                                        \n"
          ]
        }
      ]
    }
  ]
}